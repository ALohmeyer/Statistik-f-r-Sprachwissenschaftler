Statistik für Sprachwissenschaftler
========================================================
author: Phillip M . Alday
date: 2014-05-12   
autosize: false

```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE,prompt=TRUE)
library(knitcitations)
library(ggplot2)
library(reshape2)
cite_options(tooltip = TRUE
             , linked = TRUE
             , numerical = TRUE
             , bibtex_data = FALSE)
```


Aufwachen und sich errinnern!
====================================
type: section


Bisher
===============
- Von Häufigkeitsverteilung zu Wahrscheinlichkeitsverteilungen
- Standardisierung von Verteilungen
- Einige wichtige Verteilungen
- (Population vs. Stichprobe)
- Anwendung der Verteilungen: Inferenzstatistik
- Frequentism vs. Bayesianism
- Fehlerarten
- $p$-Werte

Heute
=======
- Mehr zu Stichproben
- Vergleich von Gruppen ($t$-Test)
- Confidence-Intervale

Morgen
========
- was wir heute nicht schaffen
- evtl. [BEST](http://www.indiana.edu/~kruschke/BEST/) (etwa bayes'scher $t$-Test) und Credible-Intervale  
- Interferenz in der Praxis: Der Sinn von statischen Tests, neuartige Fehler 

p-Werte
===========
- In Publikationen werden meist sogenannte p-Werte berichtet
- $p$-Wert = das beobachtete Signifikanzniveau
- Ermittlung wieder über die Prüfgröße
- bei einem einseitigen Test entspricht der p-Wert der Fläche, die unter der Standardnormalverteilung durch die Prüfgröße abgeschnitten wird im Beispiel (Lernmethode): p-Wert = $P(z > 1,73) = 0.042$
- dazu: Tabellen
- oder: R `pnorm()`
- ganz oft falsch verstanden

Das eigentliche Problem mit NHST und p-Werten
===============================================
incremental: true
Welche Frage haben wir gestellt und welche Frage beantworten wir?
- $P(H_0|E) \neq P(E|H_0)$
  - Keine Aussage, wie wahrscheinlich $H_1$ ist
  - Keine Aussage, wie wahrscheinlich $H_0$ ist
- Vergleichsbasis ("The Null is never true")

Das eigentliche Problem mit NHST und p-Werten
===============================================
incremental: true
Welche Frage haben wir gestellt und welche Frage beantworten wir?
- Existenz vs. Form 
  - Parameterschätzung
  - Effektgröße
  - ...
- Messen "Effort" (*Aufwand*) `r citep("http://www.johnmyleswhite.com/notebook/2012/07/17/criticism-5-of-nhst-p-values-measure-effort-not-truth/")`

Andere Schwierigkeiten (mehr später)
======================================
- multiples Testen (v.a. bei frequentistischen Tests)
- optional Stopping
- ....

Stichprobe vs. Population
====================================
type: section

Zentrale Thematik der schließenden Statistik
=================================================
incremental: true
Testen von statistischen Hypothesen 
  - eine statistische Hypothese wird in Bezug auf einen/mehrere Populationsparameter formuliert
  - es wird die Wahrscheinlichkeit bestimmt, mit der eine Stichprobe relativ zur Gesamtpopulation auftritt

Wie kann man aufgrund von Stichprobendaten auf zugrundeliegende Populationen schließen?

Zentrale Thematik der schließenden Statistik
=================================================
incremental: true
Schätzung von (unbekannten) Populationsparametern
  - mit welcher Sicherheit kann von beobachteten Ereignissen auf allgemeine Gesetzmäßigkeiten geschlossen werden?
  - d.h. woran erkennt man, was eine gute Schätzung ist?


Beispiel: Begabungstest für Schüler
=======================================
- 100 Aufgaben (entweder richtig oder falsch), daher Messwerte zwischen 0 und 100
- Mit 150 Schülern durchgeführt
- Populationsmittelwert $\mu = 66.73$; Populationsstandardabweichung
$\sigma = 15.86$
-  Was passiert nun, wenn wir wiederholt Stichproben unterschiedlichen Umfangs aus der Population ziehen?

Wiederholte Stichprobenziehungen (k = 25), Umfang variiert (n = 10,20,30)
========================================================================================
```{r echo=FALSE}
population <- rnorm(150,mean=66.73,sd=15.86)
n10 <- replicate(25, sample(population,10))
n20 <- replicate(25, sample(population,20))
n30 <- replicate(25, sample(population,30))
n10.mean <- apply(n10,2,mean)
n20.mean <- apply(n20,2,mean)
n30.mean <- apply(n30,2,mean)
sim.mean <- data.frame("n=10"=n10.mean,"n=20"=n20.mean,"n=30"=n30.mean)
# "correct" the R sd formula for demonstrative purposes
n10.sd <- apply(n10,2,sd)*(10-1)/10
n20.sd <- apply(n20,2,sd)*(20-1)/20
n30.sd <- apply(n30,2,sd)*(30-1)/30
sim.sd <- data.frame("n=10"=n10.sd,"n=20"=n20.sd,"n=30"=n30.sd)

head(sim.mean)
tail(sim.mean)
```

Beobachtungen
===============
- Stichprobenmittelwerte als Schätzwerte für den Populationsmittelwert?
  - stichprobenspezifischer Fehler (zufälliger Schätzfehler), der von der zufälligen Zusammensetzung der Stichprobe abhängt (z.B. davon, ob zufälligerweise Ausreißer- oder Extremwerte mit eingeflossen sind)

- Zwei systematische Muster:
  - Kleine Abweichungen zwischen dem Stichprobenmittelwert und dem Populationsmittelwert kommen häufiger vor als große
 Abweichungen
  - Die Größe der Schätzfehler nimmt mit der Stichprobengröße ab

Wiederholte Stichprobenziehungen (k = 25), Umfang variiert (n = 10,20,30)
========================================================================================
```{r echo=FALSE}
head(sim.sd)
tail(sim.sd)
```

Stichprobenkennwerteverteilung von Stichprobenmittelwerten bei n = 10, 20, 30
===============================================================================

Beobachtungen
=======================
- Der Mittelwert der Stichprobenmittelwerte liegt recht nahe am Populationsmittelwert
  - näher bei größerer Stichprobengröße
- Geringere Streuung bei größeren Stichproben
- Schätzung des Populationsmittelwerts wird also mit größer werdenden Stichproben genauer
  - geringere Wahrscheinlichkeit, dass die Stichprobe überwiegend extreme Werte enthält


Erwartungswert und Standardfehler
=====================================
- Geht die Anzahl der gezogenen Stichproben gegen unendlich, näher sich der Mittelwert der Stichprobenmittelwerte dem Populationsmittelwert an
- Standardfehler des Mittelwerts
    - $\sigma_\bar{x} = \sqrt{\frac{\sigma_x^2}{n}} = \frac{\sigma_x}{\sqrt{n}}$ 
    - Ein Mittelwert ist ein umso besserer Schätzer des Populationsmittels, desto geringer der Standardfehler
- Standardfehler wird kleiner bei größerem Stichprobenumfang

Noch einmal zurück zum z-Test
===============================
- Prüfgröße für einen $z$-Test:
  $$ z = \sqrt{n} \left(\frac{\bar{x}-\mu_0}{\sigma}\right)$$
- Aber der Standardfehler ist: 
  $$\sigma_\bar{x} = \frac{\sigma_x}{\sqrt{n}}$$ 
- und so:
$$z = \frac{\bar{x}-\mu}{\sigma\bar{_x}} $$ 

Stichprobenvarianz und Stichprobenstandardabweichung
============================================================
- Der Stichprobenmittelwert ist ein erwartungstreuer Schätzer des Populationsmittelwerts
- Dies gilt allerdings nicht für die Stichprobenvarianz bzw. -standardabweichung: systematische Unterschätzung der Populationsvarianz um den Faktor $n/(n-1)$
- Daher: Multiplikation der empirischen Varianz durch diesen Faktor
- Stichprobenvarianz:
  $$\hat{\sigma}_x^2 = \frac{\sum_i=1^n (x_i - \bar{x})^2}{n-1} = \sigma_x^2 \cdot \frac{n}{n-1} $$


Standardfehler bei unbekannter Populationsvarianz
========================================================
- Da wir meist die Populationsvarianz nicht kennen, müssen wir auch die Berechnung des Standardfehlers anpassen

- Varianz wird durch die Stichprobenvarianz ersetzt
$$\hat{\sigma}_\bar{x} = \sqrt{\frac{\hat{\sigma}_x^2}{n}} = \sqrt{\frac{s_x^2}{n-1}} $$ 


Zusammenfassung der Notation
==============================
|            | Mittelwert | Varianz          | Standardweichung |
|------------|------------|------------------|------------------|
| empirisch  |  $\bar{x}$ | $s^2$            | $s$              |
| Stichprobe |  $\bar{x}$ | $\hat{\sigma}^2$ | $\hat{\sigma}$   |
| Population |  $\mu$     | $\sigma^2$       | $\sigma$         |


Gedächtnistraining 
======================================
- Populationsverteilung der Testwerte: $\mu$ = 50,$\sigma^2$= 100
- Mittelwert in der Gruppe der trainierten Personen: $\bar{x}$ = 58
- Annahme: $n$ = 12 (Stichprobe)

Hypothesen testen bei unbekannter Populationsvarianz
======================================================
- Was ist, wenn wir bei unserem Gedächtnistest die Populationsvarianz nicht gekannt hätten, sondern nur den Erwartungswert unter der Nullhypothese? 
- $z$-Test geht nicht:
  $$z_\bar{x} = \frac{\bar{x}-\mu}{\sigma_\bar{x}} $$ 
- Nun wird die Prüfgröße $t$ mit dem aus der Stichprobenstandardabweichung geschätzen Standardfehler berechnet:
$$t_\bar{x} = \frac{\bar{x}-\mu}{\hat{\sigma}_\bar{x}} $$ 

Hypothesen testen bei unbekannter Populationsvarianz
======================================================
- Annahme, $\hat{\sigma}^2 = 114.95$ 
- $\hat{\sigma}_\bar{x} = \sqrt{\frac{\hat{\sigma}^2}{n-1}} = \sqrt{\frac{114.95}{12-1}} = 3.23$
- $t_\bar{x} = \frac{\bar{x}-\mu}{\hat{\sigma}_\bar{x}}$  
- $t_\bar{x} = \frac{58-50}{3.23} =2.48$ 

t-Test (hier: Einstichproben t-Test)
==============================================
- Die Prüfgröße $t$ folgt einer $t$-Verteilung. Bei großem $n$ geht sie in eine Standardnormalverteilung über. Bei kleinem $n$ ist sie breiter als die Standardnormalverteilung 
- Verteilung hängt von der Anzahl der Freiheitsgrade ab
- Freiheitsgrade (df für *degress of freedom*) = $n-1$

t-Test (hier: Einstichproben t-Test)
==============================================
- Unser Wert 2.48 hat bei einem einseitigen Test mit df = 11 eine Wahrscheinlichkeit von $p$ = 0.015. Damit wird die Nullhypothese
abgelehnt
```{r}
1 - pt(2.48,df=11)
```
- kritischer Wert bei einem einseitigen Test, df = 11, $\alpha$ = 0.05: 1.80
```{r}
qt(0.95,df=11)
```
4

t-Verteilung
===================
```{r echo=FALSE}
curve(dt(x,100),-3,3)
curve(dt(x,1),-3,3,add=T,lty=2)
curve(dt(x,10),-3,3,add=T,lty=3)
legend("topright",c("df=1","df=10","df=100"),lty=c(2,3,1))
```


Vergleich von Gruppen
====================================
type: section

Bibliography
=============
```{r, echo=FALSE,results='hide'}
```
<span style="font-size: 10%;">
```{r,results='asis',echo=FALSE}
bibliography(style="markdown",bulleted=FALSE)
```
</span>
